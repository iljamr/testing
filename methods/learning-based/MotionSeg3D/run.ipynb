{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MotionSeg3D\n",
    "## Generate Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using clib by $export PYTHONPATH=$PYTHONPATH:<path-to-library>\n",
      "Currently using python-lib to generate range images.\n",
      "\u001b[38;5;247mic\u001b[39m\u001b[38;5;245m|\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;247mconfig\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m{\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mcalib_file\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m/home/vscode/testing/methods/learning-based/MotionSeg3D/data/sequences/00/calib.txt\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mdebug\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36minput_base_folder\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m/home/vscode/testing/methods/learning-based/MotionSeg3D/data/sequences\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mnormalize\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;100mTrue\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mnum_frames\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m-\u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mnum_last_n\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m1\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36moutput_base_folder\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m/home/vscode/data/kitti/SemanticKITTI/motionseg3d/outputs\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mpose_file\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m/home/vscode/testing/methods/learning-based/MotionSeg3D/data/sequences/00/poses.txt\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mrange_image\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m{\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mfov_down\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;245m-\u001b[39m\u001b[38;5;36m25.0\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m                             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mfov_up\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m3.0\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m                             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mheight\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m64\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m                             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mmax_range\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m50.0\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m                             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mmin_range\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2.0\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m                             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mwidth\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m2048\u001b[39m\u001b[38;5;245m}\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mresidual_image_folder\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m/home/vscode/data/kitti/SemanticKITTI/motionseg3d/outputs/sequences/00/residual_images_1\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mscan_folder\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m/home/vscode/testing/methods/learning-based/MotionSeg3D/data/sequences/00/velodyne\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36msequence\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mNone\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mvisualization_folder\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36m/home/vscode/data/kitti/SemanticKITTI/motionseg3d/outputs/sequences/00/visualization_1\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m,\u001b[39m\n",
      "\u001b[38;5;245m             \u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;36mvisualize\u001b[39m\u001b[38;5;36m'\u001b[39m\u001b[38;5;245m:\u001b[39m\u001b[38;5;245m \u001b[39m\u001b[38;5;100mFalse\u001b[39m\u001b[38;5;245m}\u001b[39m\n",
      "generate training data for all frames with number of:  4541\n",
      "  4%|█▍                                      | 169/4541 [00:10<04:31, 16.08it/s]"
     ]
    }
   ],
   "source": [
    "!python utils/auto_gen_residual_images.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "INTERFACE:\n",
      "  dataset ./data\n",
      "  log ./pred/oursv2\n",
      "  model ./log/motionseg3d_pointrefine\n",
      "  infering valid\n",
      "  pointrefine False\n",
      "----------\n",
      "\n",
      "\u001b[32m Opening arch config file ./log/motionseg3d_pointrefine/arch_cfg.yaml\u001b[0m\n",
      "\u001b[32m Opening arch config file ./log/motionseg3d_pointrefine/data_cfg.yaml\u001b[0m\n",
      "valid : 08\n",
      "\u001b[32m model folder exists! Using model from ./log/motionseg3d_pointrefine \u001b[0m\n",
      "Sequences folder exists! Using sequences from ./data/sequences\n",
      "parsing seq 08\n",
      "\u001b[32m There are 4071 frames in total. \u001b[0m\n",
      "\u001b[32m Using 4071 scans from sequences [8]\u001b[0m\n",
      "Channel of range image input =  5\n",
      "Number of residual images input =  8\n",
      "********************************************************************************\n",
      "Cleaning point-clouds with kNN post-processing\n",
      "kNN parameters:\n",
      "knn: 5\n",
      "search: 5\n",
      "sigma: 1.0\n",
      "cutoff: 1.0\n",
      "nclasses: 3\n",
      "********************************************************************************\n",
      "Infering in device:  cuda\n",
      "  0%|                                                  | 0/4071 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"infer.py\", line 38, in <module>\n",
      "    user.infer()\n",
      "  File \"/home/vscode/testing/methods/learning-based/MotionSeg3D/modules/user.py\", line 108, in infer\n",
      "    self.infer_subset(loader=self.parser.get_valid_set(),\n",
      "  File \"/home/vscode/testing/methods/learning-based/MotionSeg3D/modules/user.py\", line 154, in infer_subset\n",
      "    for i, (proj_in, proj_mask, _, _, path_seq, path_name,\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/tqdm/std.py\", line 1180, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/_utils.py\", line 434, in reraise\n",
      "    raise exception\n",
      "IndexError: Caught IndexError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \".//common/dataset/kitti/parser.py\", line 239, in __getitem__\n",
      "    exec(\"residual_file_\" + str(i+1) + \" = \" + \"self.residual_files_\" + str(i+1) + \"[seq][index]\")\n",
      "  File \"<string>\", line 1, in <module>\n",
      "IndexError: list index out of range\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python infer.py -d ./data -m ./log/motionseg3d_pointrefine -l ./pred/oursv2 -s valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python infer.py -d ./toydata -m ./log/motionseg3d_pointrefine -l ./pred/oursv2 -s valid --pointrefine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python utils/evaluate_mos.py -d ./toydata -p ./pred/oursv2/ --datacfg config/labels/semantic-kitti-mos.raw.yaml\n",
    "#!python train.py -d /home/vscode/data/kitti/SemanticKITTI/symlinks/motionseg3d -ac ./train_yaml/mos_coarse_stage.yml -l log/ours_motionseg3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "### Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -d /home/vscode/data/kitti/SemanticKITTI/symlinks/motionseg3d -ac ./train_yaml/mos_coarse_stage.yml -l log/ours_motionseg3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -d /home/vscode/data/kitti/SemanticKITTI/symlinks/motionseg3d -ac ./train_yaml/mos_pointrefine_stage.yml -l log/ours_motionseg3d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
